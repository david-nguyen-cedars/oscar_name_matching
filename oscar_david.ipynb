{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c4da28-4e1f-4c3e-b687-6623dee9bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORT LIBRARIES AND PACKAGES \n",
    "'''\n",
    "#libraries for data manipulation and analysis \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "#libraries for date and time handling \n",
    "from dateutil import parser\n",
    "import datetime\n",
    "\n",
    "\n",
    "#libraries for excel formatting \n",
    "from openpyxl.utils.cell import get_column_letter\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import CellIsRule\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "#libraries for string similarity and fuzzy matching \n",
    "import jellyfish\n",
    "from Levenshtein import distance as ld\n",
    "from fuzzywuzzy import fuzz\n",
    "import textdistance as td\n",
    "\n",
    "#libraries with general utility functions \n",
    "import random\n",
    "import os\n",
    "from termcolor import cprint\n",
    "from collections import _count_elements \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bae3677-a41c-455e-b599-9e395718be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for output files\n",
    "file_modifier = \"david_test1\"\n",
    "output_pathway = r'C:\\Users\\NguyenD29\\OneDrive - Cedars-Sinai Health System\\Documents\\Trainings\\Marco Documentation\\OSCAR_name_matching\\oscar_name_matching\\outputs' \n",
    "\n",
    "#flags\n",
    "remove_var = 1 \n",
    "drop_pat_ids = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92b78c-8315-4638-a604-0a8e04cfaf9c",
   "metadata": {},
   "source": [
    "## BRING IN FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6933d271-fd5a-4226-ac18-1608246b7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in files - mr: medical records, dc: death certificates \n",
    "medical_records = pd.read_excel(r\"C:\\Users\\NguyenD29\\OneDrive - Cedars-Sinai Health System\\Documents\\Trainings\\Marco Documentation\\OSCAR_name_matching\\oscar_name_matching\\data\\ForDeathCertMatch_7_17_2025.xlsx\", dtype = 'string')\n",
    "death_certs = pd.read_excel(r\"C:\\Users\\NguyenD29\\OneDrive - Cedars-Sinai Health System\\Documents\\Trainings\\Marco Documentation\\OSCAR_name_matching\\oscar_name_matching\\data\\Norby_CCDF_040125_063025.xlsx\", dtype = 'string')\n",
    "gender = pd.read_excel(r'C:\\Users\\NguyenD29\\OneDrive - Cedars-Sinai Health System\\Documents\\Trainings\\Marco Documentation\\OSCAR_name_matching\\oscar_name_matching\\data\\oscar_gender.xlsx', dtype={'strMRN' : str, 'gender' : str}) \n",
    "\n",
    "df = medical_records.copy()\n",
    "matchto = death_certs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "298d5b50-bb62-4bb7-89c1-47feb0c4f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No column overlap detected\n"
     ]
    }
   ],
   "source": [
    "#checking for columns with same name in medical records and death certificate files \n",
    "overlap = set(medical_records.columns) & set(death_certs.columns)\n",
    "\n",
    "#if there is an overlap\n",
    "if len(overlap) > 0:\n",
    "    #rename column in death_certs (we will match to it later) \n",
    "    raise Exception(f'Column overlap detected: {overlap}. Renaming in death certificates dataframe')\n",
    "\n",
    "    for col in overlap:\n",
    "        death_certs = death_certs.rename(columns = {col: col+'_matchto'})\n",
    "        print(f'Renaming column from {col} to {col+\"_matchto\"}') \n",
    "else: \n",
    "    print('No column overlap detected')\n",
    "\n",
    "#checking for commas in column names - need to change them in the input file \n",
    "erroneouslist_dc = list()\n",
    "for col in list(death_certs.columns):\n",
    "    if ',' in col:\n",
    "        erroneouslist_dc.append(col)\n",
    "        \n",
    "erroneouslist_mr = list()\n",
    "for col in list(medical_records.columns):\n",
    "    if ',' in col:\n",
    "        erroneouslist_mr.append(col)\n",
    "    \n",
    "if len(erroneouslist_dc) > 0:\n",
    "    raise Exception('PLEASE FIX:\\nThere are commas (,) found in the following death_certs columns: {}\\nThese will cause problems later down the line. Please manually change them in the input file.'.format(erroneouslist_dc))\n",
    "if len(erroneouslist_mr) > 0:\n",
    "    raise Exception('PLEASE FIX:\\nThere are commas (,) found in the following medical_records columns: {}\\nThese will cause problems later down the line. Please manually change them in the input file.'.format(erroneouslist_mr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f24ddea-7593-4533-8dfd-fcb1157825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split name into first, middle, last for medical records dataframe \n",
    "if 'PAT_NAME' in medical_records:\n",
    "    medical_records['First Name'] = medical_records['PAT_NAME'].apply(lambda x : x.split(',')[1].split(' ')[0]) \n",
    "    medical_records['Middle Name'] = medical_records['PAT_NAME'].apply(lambda x : x.split(',')[1].split(' ')[1] if ' ' in x.split(',')[1] else None) \n",
    "    medical_records['Last Name'] = medical_records['PAT_NAME'].apply(lambda x : x.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "855b790b-7af6-404b-8714-f88dd7776cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_records = df.copy()\n",
    "death_certs = matchto.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19521b-ded6-4439-88ea-ecb889daff07",
   "metadata": {},
   "source": [
    "## CLEAN SOCIAL SECURITY NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77c99827-9634-4099-8717-2120b7e16c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssn_cleaner(x, invalid_ssns):\n",
    "    '''\n",
    "    function to process ssn to filter for ssns that would be considered invalid \n",
    "    - more than six 0's\n",
    "    - more than seven 1's\n",
    "    - more than six 9's\n",
    "    - all 0's and 1's \n",
    "    '''\n",
    "    #replace trailing 0 \n",
    "    x = x.replace('.0', '')\n",
    "\n",
    "    #return nothing if ssn is in invalid ssns list \n",
    "    if x in invalid_ssns:\n",
    "        return None\n",
    "\n",
    "    #add leading 0's\n",
    "    x = '0'*(9-len(x)) + str(x)\n",
    "\n",
    "    #find counts of each digit and return none for invalid ssns \n",
    "    digit_counts = Counter(x)\n",
    "    if digit_counts['0'] > 6 or digit_counts['1'] > 7 or digit_counts['9'] > 6 or digit_counts.keys() == {0,1}: \n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "\n",
    "#clean up ssn column in medical records dataframe\n",
    "if 'SSN' in medical_records.columns:\n",
    "    #clean up dashes\n",
    "    medical_records['SSN'] = medical_records['SSN'].apply(lambda x: str(x).replace('-', ''))\n",
    "\n",
    "    #get invalid ssns - threshold is if there is 4 or more of the same one\n",
    "    counts = medical_records['SSN'].value_counts().to_frame().reset_index()\n",
    "    invalid_ssn = counts[counts['count'] > 4]['SSN'].to_list()\n",
    "    invalid_ssn += ['<NA>', 'nan', None, '123456789', '0', 0]\n",
    "\n",
    "    #use helper function to clean ssn \n",
    "    medical_records['SSN'] = medical_records['SSN'].apply(lambda x: ssn_cleaner(x, invalid_ssn))\n",
    "\n",
    "\n",
    "#clean up ssn in death certificates dataframe\n",
    "if 'F31' in death_certs.columns: \n",
    "    #clean up dashes\n",
    "    death_certs['F31'] = death_certs['F31'].apply(lambda x: str(x).replace('-', ''))\n",
    "\n",
    "    #get invalid ssns - threshold is if there is 4 or more of the same one\n",
    "    counts = death_certs['F31'].value_counts().to_frame().reset_index()\n",
    "    invalid_ssn = counts[counts['count'] > 4]['F31'].to_list()\n",
    "    invalid_ssn += ['<NA>', 'nan', None, '123456789', '0', 0]\n",
    "\n",
    "    #use helper function to clean ssn \n",
    "    death_certs['F31'] = death_certs['F31'].apply(lambda x: ssn_cleaner(x, invalid_ssn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492f0fd-506b-407c-8a74-4125868b3f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e16aadc2-cf0a-41b9-a4d7-8c3c1decce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# COLUMN ASSOCIATION CHUNK\n",
    "\n",
    "### NORMAL RUN!\n",
    "dfdob = 'BIRTH_DATE' #make this a tkinter menu later - modify code from FullSuiteGeolocation header - picking columns from drop down list\n",
    "dfdod = 'DEATH_DATE'\n",
    "dffn = 'First Name'\n",
    "dfmn = 'Middle Name'\n",
    "dfln = 'Last Name'\n",
    "dfunids = ['PAT_ID']\n",
    "dfaddress = 'ADD_LINE_1'\n",
    "dfsex = 'GENDER'\n",
    "dfarrestloc_a = 'BlankCol_df1'\n",
    "dfarrestloc_b = 'BlankCol_df2'\n",
    "\n",
    "## ONE OFF AUTOPSY RUN:\n",
    "# dfdob = 'Demographics.DATE OF BIRTH'\n",
    "# dfdod = 'Date of death'\n",
    "# dffn = 'First Name'\n",
    "# dfmn = 'Middle Name'\n",
    "# dfln = 'Last Name'\n",
    "# dfunids = ['SUDS #']\n",
    "# dfaddress = 'BlankCol_df'\n",
    "# dfsex = 'BlankCol_df'\n",
    "# dfarrestloc_a = 'BlankCol_df'\n",
    "# dfarrestloc_b = 'BlankCol_df'\n",
    "\n",
    "# ## ORIGINAL RUN\n",
    "# matchtodob = 'DOB'\n",
    "# matchtodod = 'DOD'\n",
    "# matchtofn = 'FNAME'\n",
    "# matchtomn = 'MNAME'\n",
    "# matchtoln = 'LNAME' #see above\n",
    "# matchtotarget = 'Snumber'\n",
    "# matchtounids = ['Snumber']\n",
    "# matchtoaddress = 'ADDR1'\n",
    "# matchtoaddress2 = 'ADDR2' #\n",
    "# matchtocity = 'CITY_matchto'\t #\n",
    "# matchtosex = 'SEX' #\n",
    "\n",
    "## DC RUN\n",
    "# matchtodob = 'dob'\n",
    "# matchtodod = 'dod'\n",
    "# matchtofn = 'First_name'\n",
    "# matchtomn = 'middle_name'\n",
    "# matchtoln = 'last_name' #see above\n",
    "# matchtotarget = 'SFN'\n",
    "# matchtounids = ['SFN']\n",
    "# matchtoaddress = 'home addr1'\n",
    "# matchtoaddress2 = 'home_addre' #\n",
    "# matchtocity = 'home_city'\t #\n",
    "\n",
    "## New Combined CCDF Norby run\n",
    "matchtodob = 'F8'\n",
    "matchtodod = 'F20'\n",
    "matchtofn = 'F3'\n",
    "matchtomn = 'F4'\n",
    "matchtoln = 'F5' #see above\n",
    "matchtotarget = 'F1'\n",
    "matchtounids = ['F1']\n",
    "matchtoaddress = 'F55'\n",
    "matchtoaddress2 = 'F56' #\n",
    "matchtocity = 'F57'\t #\n",
    "matchtosex = 'F19' #have to get this column from \"C:\\Users\\MathiasM\\Box\\OSCAR Death data\\Norby_CCDF_010123_063024_combined.xlsx\"\n",
    "matchtodoa = 'BlankCol_matchto1'\n",
    "matchtossn = 'F31'\n",
    "matchtoarrestloc_a = 'F132'\n",
    "matchtoarrestloc_b = 'F133'\n",
    "matchtoaddress_arrest_city = 'F134'\n",
    "\n",
    "##One-off autopsy run:\n",
    "# matchtodob = 'Identification - Date of birth'\n",
    "# matchtodod = \"Identification - Date of death\"\n",
    "# matchtofn = 'Identification - First name'\n",
    "# matchtomn = 'BlankCol_matchto'\n",
    "# matchtoln = 'Identification - Last name'\n",
    "# matchtotarget = \"Identification - Case number\"\n",
    "# matchtounids = [\"Identification - Case number\"]\n",
    "# matchtoaddress = 'BlankCol_matchto'\n",
    "# matchtoaddress2 = 'BlankCol_matchto'\n",
    "# matchtocity = 'BlankCol_matchto'\n",
    "# matchtosex = 'BlankCol_matchto'\n",
    "# matchtodoa = 'BlankCol_matchto'\n",
    "#matchtossn \n",
    "\n",
    "# matchtoarrestloc_a = 'BlankCol_matchto'\n",
    "# matchtoarrestloc_b = 'BlankCol_matchto'\n",
    "# matchtoaddress_arrest_city = 'BlankCol_matchto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c5be8-0cff-4ec0-9873-cb1c7761a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# COLUMN ASSOCIATION CHUNK\n",
    "\n",
    "### NORMAL RUN!\n",
    "medical_record_dob = 'BIRTH_DATE' #make this a tkinter menu later - modify code from FullSuiteGeolocation header - picking columns from drop down list\n",
    "medical_record_dod = 'DEATH_DATE'\n",
    "medical_record_fn = 'First Name'\n",
    "medical_record_mn = 'Middle Name'\n",
    "medical_record_ln = 'Last Name'\n",
    "medical_record_unids = ['PAT_ID']\n",
    "medical_record_address = 'ADD_LINE_1'\n",
    "medical_record_sex = 'GENDER'\n",
    "medical_record_arrestloc_a = 'BlankCol_medical_record1'\n",
    "medical_record_arrestloc_b = 'BlankCol_medical_record2'\n",
    "\n",
    "## ONE OFF AUTOPSY RUN:\n",
    "# medical_record_dob = 'Demographics.DATE OF BIRTH'\n",
    "# medical_record_dod = 'Date of death'\n",
    "# medical_record_fn = 'First Name'\n",
    "# medical_record_mn = 'Middle Name'\n",
    "# medical_record_ln = 'Last Name'\n",
    "# medical_record_unids = ['SUDS #']\n",
    "# medical_record_address = 'BlankCol_medical_record'\n",
    "# medical_record_sex = 'BlankCol_medical_record'\n",
    "# medical_record_arrestloc_a = 'BlankCol_medical_record'\n",
    "# medical_record_arrestloc_b = 'BlankCol_medical_record'\n",
    "\n",
    "# ## ORIGINAL RUN\n",
    "# death_certs_dob = 'DOB'\n",
    "# death_certs_dod = 'DOD'\n",
    "# death_certs_fn = 'FNAME'\n",
    "# death_certs_mn = 'MNAME'\n",
    "# death_certs_ln = 'LNAME' #see above\n",
    "# death_certs_target = 'Snumber'\n",
    "# death_certs_unids = ['Snumber']\n",
    "# death_certs_address = 'ADDR1'\n",
    "# death_certs_address2 = 'ADDR2' #\n",
    "# death_certs_city = 'CITY_death_certs_'\t #\n",
    "# death_certs_sex = 'SEX' #\n",
    "\n",
    "## DC RUN\n",
    "# death_certs_dob = 'dob'\n",
    "# death_certs_dod = 'dod'\n",
    "# death_certs_fn = 'First_name'\n",
    "# death_certs_mn = 'middle_name'\n",
    "# death_certs_ln = 'last_name' #see above\n",
    "# death_certs_target = 'SFN'\n",
    "# death_certs_unids = ['SFN']\n",
    "# death_certs_address = 'home addr1'\n",
    "# death_certs_address2 = 'home_addre' #\n",
    "# death_certs_city = 'home_city'\t #\n",
    "\n",
    "## New Combined CCDF Norby run\n",
    "death_certs_dob = 'F8'\n",
    "death_certs_dod = 'F20'\n",
    "death_certs_fn = 'F3'\n",
    "death_certs_mn = 'F4'\n",
    "death_certs_ln = 'F5' #see above\n",
    "death_certs_target = 'F1'\n",
    "death_certs_unids = ['F1']\n",
    "death_certs_address = 'F55'\n",
    "death_certs_address2 = 'F56' #\n",
    "death_certs_city = 'F57'\t #\n",
    "death_certs_sex = 'F19' #have to get this column from \"C:\\Users\\MathiasM\\Box\\OSCAR Death data\\Norby_CCDF_010123_063024_combined.xlsx\"\n",
    "death_certs_doa = 'BlankCol_death_certs1'\n",
    "death_certs_ssn = 'F31'\n",
    "death_certs_arrestloc_a = 'F132'\n",
    "death_certs_arrestloc_b = 'F133'\n",
    "death_certs_address_arrest_city = 'F134'\n",
    "\n",
    "##One-off autopsy run:\n",
    "# death_certs_dob = 'Identification - Date of birth'\n",
    "# death_certs_dod = \"Identification - Date of death\"\n",
    "# death_certs_fn = 'Identification - First name'\n",
    "# death_certs_mn = 'BlankCol_death_certs'\n",
    "# death_certs_ln = 'Identification - Last name'\n",
    "# death_certs_target = \"Identification - Case number\"\n",
    "# death_certs_unids = [\"Identification - Case number\"]\n",
    "# death_certs_address = 'BlankCol_death_certs'\n",
    "# death_certs_address2 = 'BlankCol_death_certs'\n",
    "# death_certs_city = 'BlankCol_death_certs'\n",
    "# death_certs_sex = 'BlankCol_death_certs'\n",
    "# death_certs_doa = 'BlankCol_death_certs'\n",
    "# death_certs_ssn \n",
    "\n",
    "# death_certs_arrestloc_a = 'BlankCol_death_certs'\n",
    "# death_certs_arrestloc_b = 'BlankCol_death_certs'\n",
    "# death_certs_address_arrest_city = 'BlankCol_death_certs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e38c48-7433-4e6e-a69f-6f67b8bb89a0",
   "metadata": {},
   "source": [
    "## QUESTION\n",
    "- do we need to keep this naming section?\n",
    "- we end up deleting themall too\n",
    "- also why does it only delete the last var? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26c066ed-d3d8-423b-9318-281d23a68614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed dfarrestloc_a from BlankCol_df1 to BlankCol_df11\n",
      "Renamed dfarrestloc_b from BlankCol_df2 to BlankCol_df22\n",
      "Renamed matchtodoa from BlankCol_matchto1 to BlankCol_matchto13\n"
     ]
    }
   ],
   "source": [
    "bc_matchto = []\n",
    "bc_df = []\n",
    "count_m = 1\n",
    "\n",
    "for var in list(locals()):\n",
    "    if 'matchto' in var:\n",
    "        if type(eval(var)) == str:\n",
    "           if 'blankcol' in eval(var).lower() and '_first' not in eval(var).lower():\n",
    "                print('Renamed {} from {} to {}'.format(var, eval(var), eval(var)+str(count_m)))\n",
    "\n",
    "                exec(\"{}='{}{}'\".format(var, eval(var), count_m))\n",
    "\n",
    "                count_m = count_m + 1\n",
    "                bc_matchto.append(eval(var)) #bc var already changed, don't need to append count_m\n",
    "                if eval(var) not in matchto.columns:\n",
    "                    matchto.insert(matchto.shape[1], eval(var), None)\n",
    "    if 'df' in var:\n",
    "        if type(eval(var)) == str:\n",
    "            if 'blankcol' in eval(var).lower() and '_first' not in eval(var).lower():\n",
    "                print('Renamed {} from {} to {}'.format(var, eval(var), eval(var)+str(count_m)))\n",
    "\n",
    "                exec(\"{}='{}{}'\".format(var, eval(var), count_m))\n",
    "                \n",
    "                count_m = count_m + 1\n",
    "                bc_df.append(eval(var)) #bc var already changed, don't need to append count_m\n",
    "                if eval(var) not in df.columns:\n",
    "                    df.insert(df.shape[1], eval(var), None)\n",
    "\n",
    "del bc_matchto, bc_df, count_m, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f53192-cf40-48d5-b08f-dff3b6b3d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if not 'BlankCol_matchto1' in matchto.columns:\n",
    "#     matchto.insert(matchto.shape[1], 'BlankCol_matchto1', None) #changed default value from '' to None, could cause errors. Alternative is to update subfuncs s.t they account\n",
    "#     #for blank strings. Notably date_diffs_noabs\n",
    "# if not 'BlankCol_matchto2' in matchto.columns:\n",
    "#     matchto.insert(matchto.shape[1], 'BlankCol_matchto2', None)\n",
    "# if not 'BlankCol_df1' in df.columns:\n",
    "#     df.insert(df.shape[1], 'BlankCol_df1', None)\n",
    "# if not 'BlankCol_df2' in df.columns:\n",
    "#     df.insert(df.shape[1], 'BlankCol_df2', None)\n",
    "\n",
    "def gendertypeswitch(x): #where x is a single entry\n",
    "    if not pd.isna(x):\n",
    "        if x == 'F':\n",
    "            return '1'\n",
    "        elif x == 'M':\n",
    "            return '2'\n",
    "        elif x == '1' or x == 1: #protecting other type if present already (usually for df)\n",
    "            return '1' \n",
    "        elif x == '2' or x == 2: #protecting other type if present already (usually for df)\n",
    "            return '2'\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "preclean_gender_matchto = list(matchto[matchtosex].unique())\n",
    "preclean_gender_df = list(df[dfsex].unique())\n",
    "#matchto[matchtosex] = matchto[matchtosex].apply(lambda x : '1' if x == 'F' else '2') #priya said F = 1, M = 2. THIS IS ONLY FOR THIS CHUNK! COMMENT OUT IF NOT USING!\n",
    "matchto[matchtosex] = matchto[matchtosex].apply(lambda x : gendertypeswitch(x))\n",
    "df[dfsex] = df[dfsex].apply(lambda x : gendertypeswitch(x))\n",
    "\n",
    "\n",
    "\n",
    "#Created here:\n",
    "matchtofn2 = matchtofn+'_f2'\n",
    "matchtoln2 = matchtoln+'_f2'\n",
    "\n",
    "matchtofn3 = matchtofn+'_f3'\n",
    "matchtoln3 = matchtoln+'_f3'\n",
    "\n",
    "matchtofn1 = matchtofn+'_f1'\n",
    "matchtoln1 = matchtoln+'_f1'\n",
    "matchtoaddress_1 = matchtoaddress+\"_first\"\n",
    "\n",
    "######Created here, no need to modify:\n",
    "dffn2 = dffn+'_f2'\n",
    "dfln2 = dfln+'_f2'\n",
    "\n",
    "dffn3 = dffn+'_f3'\n",
    "dfln3 = dfln+'_f3'\n",
    "\n",
    "dffn1 = dffn+'_f1'\n",
    "dfln1 = dfln+'_f1'\n",
    "\n",
    "dfaddress_1 = dfaddress+'_first'\n",
    "\n",
    "# if 'matchtossn' in locals(): #make this more modular...\n",
    "#     matchto_columns = [matchtodob, matchtodod, matchtofn, matchtomn, matchtoln, matchtotarget, \n",
    "#                     matchtofn2, matchtoln2, matchtofn3, matchtoln3, matchtofn1, matchtoln1, matchtossn, matchtoaddress_1, matchtoaddress,\n",
    "#                     matchtoaddress2, matchtocity, matchtosex, matchtoarrestloc_a, matchtoarrestloc_b, matchtoaddress_arrest_city] #+ [i for i in matchto.columns if 'blankcol']\n",
    "# else: \n",
    "#     matchto_columns = [matchtodob, matchtodod, matchtofn, matchtomn, matchtoln, matchtotarget, \n",
    "#                     matchtofn2, matchtoln2, matchtofn3, matchtoln3, matchtofn1, matchtoln1, matchtoaddress_1, matchtoaddress,\n",
    "#                     matchtoaddress2, matchtocity, matchtosex, matchtoarrestloc_a, matchtoarrestloc_b, matchtoaddress_arrest_city]\n",
    "\n",
    "matchto_columns = []\n",
    "for var in list(locals()):\n",
    "    if str(var[0:7]) == 'matchto' and type(eval(var)) == str:\n",
    "        #print(var, var[0:7])\n",
    "        matchto_columns.append(eval(var))\n",
    "\n",
    "def date_parsing(x):\n",
    "    if not pd.isna(x):\n",
    "        try:\n",
    "            if type(x) != datetime.date:\n",
    "                return parser.parse(str(x)).date()\n",
    "            else:\n",
    "                return x\n",
    "        except Exception as e:\n",
    "            #print('Could not date parse: {} due to {}'.format(x, e))\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def DTfix(subset_string, dataframe, list_of_date_columns):\n",
    "    for z in list_of_date_columns:\n",
    "        if z in dataframe.columns:\n",
    "            print('{} {} dtype'.format(subset_string, z), type(dataframe[z].iloc[0]))\n",
    "            if type(dataframe[z].iloc[0]) != datetime.date:\n",
    "                print('Converting {} {} dtype...'.format(subset_string, z))\n",
    "                dataframe[z] = dataframe[z].apply(lambda x : date_parsing(x))\n",
    "                print('Done converting... checking...')\n",
    "                date_test = dataframe[~pd.isna(dataframe[z])][z].iloc[round(len(dataframe[~pd.isna(dataframe[z])])/2)]\n",
    "                print('     ',date_test, type(date_test),'\\n')\n",
    "        else:\n",
    "            print('Could not find {} in {}\\n'.format(z, subset_string))\n",
    "\n",
    "DTfix('df', df, [dfdob, dfdod, 'MAX_ENC_DATE'])\n",
    "DTfix('matchto', matchto, [matchtodob, matchtodod])\n",
    "\n",
    "print('\\nCleaning name columns...')\n",
    "\n",
    "def lower_spacerm_sub(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    \n",
    "    if type(x) == str:\n",
    "        return str(x).lower().replace(' ', '').replace('-','').replace(',', '').replace(\"'\", '').replace('.', '')\n",
    "   \n",
    "def lower_spacerm(dataframe, list_of_name_columns):\n",
    "    for z in list_of_name_columns:\n",
    "        dataframe[z] = dataframe[z].apply(lambda x : lower_spacerm_sub(x))\n",
    "\n",
    "lower_spacerm(df, [dffn, dfmn, dfln])\n",
    "lower_spacerm(matchto, [matchtofn, matchtomn, matchtoln])\n",
    "\n",
    "\n",
    "print('Forming \"first_*\" columns') #occurs after lower_spacerm so don't have to reapply all that stuff!\n",
    "#functionalize this!!!\n",
    "def nameshorten(x, number_of_characters):\n",
    "    if not pd.isna(x):\n",
    "        return x[0:number_of_characters]\n",
    "    else:\n",
    "        return None\n",
    "df[dffn2] = df[dffn].apply(lambda x : nameshorten(x,2))\n",
    "df[dfln2] = df[dfln].apply(lambda x : nameshorten(x,2))\n",
    "matchto[matchtofn2] = matchto[matchtofn].apply(lambda x : nameshorten(x,2))\n",
    "matchto[matchtoln2] = matchto[matchtoln].apply(lambda x : nameshorten(x,2))\n",
    "\n",
    "df[dffn3] = df[dffn].apply(lambda x : nameshorten(x,3))\n",
    "df[dfln3] = df[dfln].apply(lambda x : nameshorten(x,3))\n",
    "df[dffn1] = df[dffn].apply(lambda x : nameshorten(x,1))\n",
    "df[dfln1] = df[dfln].apply(lambda x : nameshorten(x,1))\n",
    "\n",
    "matchto[matchtofn3] = matchto[matchtofn].apply(lambda x : nameshorten(x,3))\n",
    "matchto[matchtoln3] = matchto[matchtoln].apply(lambda x : nameshorten(x,3))\n",
    "matchto[matchtofn1] = matchto[matchtofn].apply(lambda x : nameshorten(x,1))\n",
    "matchto[matchtoln1] = matchto[matchtoln].apply(lambda x : nameshorten(x,1))\n",
    "\n",
    "\n",
    "#Forming address_1\n",
    "print('Forming \"address_1\" columns')\n",
    "\n",
    "def address_split(x):\n",
    "    x=str(x)\n",
    "    if not pd.isna(x) and x != 'nan' and x != '<NA>':\n",
    "        return x.split(' ')[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df[dfaddress_1] = df[dfaddress].apply(lambda x : address_split(x))    \n",
    "matchto[matchtoaddress_1] = matchto[matchtoaddress].apply(lambda x : address_split(x))  \n",
    "\n",
    "#Also dropping duplicate rows in both:\n",
    "def dupedrop(dataframe, subset_string, list_of_unid_columns):\n",
    "    prel = len(dataframe)\n",
    "    temp = dataframe.drop_duplicates()\n",
    "    postl = len(temp)\n",
    "    print('Dropped {} duplicates from {}'.format(prel-postl, subset_string))\n",
    "\n",
    "    for idcol in list_of_unid_columns:\n",
    "        f1list=dataframe[idcol].value_counts().to_frame()\n",
    "        #f2list=dataframe['F2'].value_counts().to_frame()\n",
    "        f1list = f1list[f1list['count'] == 2]\n",
    "        #f2list = f2list[f2list['count'] == 2]\n",
    "        print(len(f1list))\n",
    "        if len(f1list) > 0:\n",
    "            print('There is a duplicate in the {} column - see the following records:\\n {}'.format(idcol, f1list))\n",
    "\n",
    "    return temp\n",
    "\n",
    "print('\\n')\n",
    "df = dupedrop(df, 'df', dfunids)\n",
    "matchto = dupedrop(matchto, 'matchto', matchtounids)\n",
    "\n",
    "df_columns = list(df.columns) + ['nametag_df'] #locking columns here so we can filter using this later!\n",
    "print(df_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oscar_venv)",
   "language": "python",
   "name": "oscar_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
